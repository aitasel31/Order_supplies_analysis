{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee469233",
   "metadata": {},
   "source": [
    "## Order supplies dataset load\n",
    "### Agenda\n",
    "* Dataset description\n",
    "* Cleaning\n",
    "* Profit outlier detection and handling\n",
    "* Country names normalization\n",
    "* Final corrections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7ad4a2",
   "metadata": {},
   "source": [
    "### Dataset description\n",
    "The DataCo Supply Chain Dataset contains detailed transactional data related to a global retail supply chain.\n",
    "Each record represents an order line item, combining information about orders, customers, products, shipping, and financial performance.\n",
    "\n",
    "**The dataset includes**:\n",
    "* Order details such as order dates, status, region, and market\n",
    "* Customer information including customer segment and location\n",
    "* Product attributes such as product name, category, price, and quantity\n",
    "* Shipping and logistics data, including shipping mode, scheduled vs. actual delivery time, and delivery status\n",
    "* Financial metrics, including sales, profit, discounts, and profit ratios\n",
    "* Geographic information, allowing country-level and regional analysis\n",
    "\n",
    "The data spans multiple years (2015-2018) and multiple countries, making it suitable for analyzing:\n",
    "* Sales and profit performance\n",
    "* Customer and product behavior\n",
    "* Shipping efficiency and delivery delays\n",
    "* Geographic and market-level trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762b1a8f",
   "metadata": {},
   "source": [
    "### Cleaning\n",
    "This part includes basic cleaning steps like: droppping, renaming columns, deleting duplicates and creating new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c4e3d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pycountry\n",
    "import os\n",
    "from deep_translator import GoogleTranslator\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b180dce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error importing huggingface_hub.hf_file_system: No module named 'cgi'\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Unable to load filesystem from EntryPoint(name='hf', value='huggingface_hub.HfFileSystem', group='fsspec.specs')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\fsspec\\registry.py:264\u001b[39m, in \u001b[36mget_filesystem_class\u001b[39m\u001b[34m(protocol)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m     register_implementation(protocol, \u001b[43m_import_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbit\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclass\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\fsspec\\registry.py:303\u001b[39m, in \u001b[36m_import_class\u001b[39m\u001b[34m(fqp)\u001b[39m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m name.split(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m303\u001b[39m     mod = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, \u001b[38;5;28mtype\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\huggingface_hub\\__init__.py:1048\u001b[39m, in \u001b[36m_attach.<locals>.__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m   1047\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1048\u001b[39m     submod = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubmod_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\importlib\\__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1398\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n\u001b[32m   1397\u001b[39m     name = _resolve_name(name, package, level)\n\u001b[32m-> \u001b[39m\u001b[32m1398\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_find_and_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1371\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n\u001b[32m   1370\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m _NEEDS_LOADING:\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_find_and_load_unlocked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimport_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[38;5;66;03m# Optimization: only call _bootstrap._lock_unlock_module() if\u001b[39;00m\n\u001b[32m   1374\u001b[39m \u001b[38;5;66;03m# module.__spec__._initializing is True.\u001b[39;00m\n\u001b[32m   1375\u001b[39m \u001b[38;5;66;03m# NOTE: because of this, initializing must be set *before*\u001b[39;00m\n\u001b[32m   1376\u001b[39m \u001b[38;5;66;03m# putting the new module in sys.modules.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1342\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n\u001b[32m   1341\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1342\u001b[39m     module = \u001b[43m_load_unlocked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:938\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n\u001b[32m    936\u001b[39m         \u001b[38;5;66;03m# A namespace package so do nothing.\u001b[39;00m\n\u001b[32m    937\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m938\u001b[39m         \u001b[43mspec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexec_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:762\u001b[39m, in \u001b[36m_LoaderBasics.exec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n\u001b[32m    760\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcannot load module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m when \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    761\u001b[39m                       \u001b[33m'\u001b[39m\u001b[33mget_code() returns None\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m762\u001b[39m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_with_frames_removed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__dict__\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:491\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n\u001b[32m    484\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"remove_importlib_frames in import.c will always remove sequences\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[33;03mof importlib frames that end with a call to this function\u001b[39;00m\n\u001b[32m    486\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    489\u001b[39m \u001b[33;03mmodule code)\u001b[39;00m\n\u001b[32m    490\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m491\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\huggingface_hub\\hf_file_system.py:16\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfsspec\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhttpx\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfsspec\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _DEFAULT_CALLBACK, NoOpCallback, TqdmCallback\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\httpx\\__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__version__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __description__, __title__, __version__\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m delete, get, head, options, patch, post, put, request, stream\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_auth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Auth, BasicAuth, DigestAuth\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\httpx\\_api.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_client\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Client, StreamContextManager\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DEFAULT_TIMEOUT_CONFIG\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\httpx\\_client.py:8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhttpcore\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_auth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Auth, BasicAuth, FunctionAuth\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     DEFAULT_MAX_REDIRECTS,\n\u001b[32m     11\u001b[39m     DEFAULT_POOL_LIMITS,\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     UnsetType,\n\u001b[32m     19\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\httpx\\_auth.py:10\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_exceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProtocolError, RequestBodyUnavailable\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Request, Response\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_bytes, to_str, unquote\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\httpx\\_models.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcgi\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'cgi'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#Load data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m raw_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhf://datasets/alalfi/SupplyChainDataset/DataCoSupplyChainDataset1.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m raw_df.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\io\\common.py:728\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    725\u001b[39m     codecs.lookup_error(errors)\n\u001b[32m    727\u001b[39m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m728\u001b[39m ioargs = \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m handle = ioargs.filepath_or_buffer\n\u001b[32m    737\u001b[39m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\io\\common.py:430\u001b[39m, in \u001b[36m_get_filepath_or_buffer\u001b[39m\u001b[34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[39m\n\u001b[32m    427\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m     file_obj = \u001b[43mfsspec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfsspec_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m.open()\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# GH 34626 Reads from Public Buckets without Credentials needs anon=True\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(err_types_to_retry_with_anon):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\fsspec\\core.py:508\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(urlpath, mode, compression, encoding, errors, protocol, newline, expand, **kwargs)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Given a path or paths, return one ``OpenFile`` object.\u001b[39;00m\n\u001b[32m    451\u001b[39m \n\u001b[32m    452\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    505\u001b[39m \u001b[33;03m  https://filesystem-spec.readthedocs.io/en/latest/api.html#other-known-implementations\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    507\u001b[39m expand = DEFAULT_EXPAND \u001b[38;5;28;01mif\u001b[39;00m expand \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m expand\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m out = \u001b[43mopen_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m    \u001b[49m\u001b[43murlpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43murlpath\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexpand\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out:\n\u001b[32m    520\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(urlpath)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\fsspec\\core.py:295\u001b[39m, in \u001b[36mopen_files\u001b[39m\u001b[34m(urlpath, mode, compression, encoding, errors, name_function, num, protocol, newline, auto_mkdir, expand, **kwargs)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mopen_files\u001b[39m(\n\u001b[32m    217\u001b[39m     urlpath,\n\u001b[32m    218\u001b[39m     mode=\u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    228\u001b[39m     **kwargs,\n\u001b[32m    229\u001b[39m ):\n\u001b[32m    230\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Given a path or paths, return a list of ``OpenFile`` objects.\u001b[39;00m\n\u001b[32m    231\u001b[39m \n\u001b[32m    232\u001b[39m \u001b[33;03m    For writing, a str path must contain the \"*\" character, which will be filled\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    293\u001b[39m \u001b[33;03m      https://filesystem-spec.readthedocs.io/en/latest/api.html#other-known-implementations\u001b[39;00m\n\u001b[32m    294\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     fs, fs_token, paths = \u001b[43mget_fs_token_paths\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43murlpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpand\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    304\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m fs.protocol == \u001b[33m\"\u001b[39m\u001b[33mfile\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    305\u001b[39m         fs.auto_mkdir = auto_mkdir\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\fsspec\\core.py:672\u001b[39m, in \u001b[36mget_fs_token_paths\u001b[39m\u001b[34m(urlpath, mode, num, name_function, storage_options, protocol, expand)\u001b[39m\n\u001b[32m    670\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m protocol:\n\u001b[32m    671\u001b[39m     storage_options[\u001b[33m\"\u001b[39m\u001b[33mprotocol\u001b[39m\u001b[33m\"\u001b[39m] = protocol\n\u001b[32m--> \u001b[39m\u001b[32m672\u001b[39m chain = \u001b[43m_un_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43murlpath0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    673\u001b[39m inkwargs = {}\n\u001b[32m    674\u001b[39m \u001b[38;5;66;03m# Reverse iterate the chain, creating a nested target_* structure\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\fsspec\\core.py:358\u001b[39m, in \u001b[36m_un_chain\u001b[39m\u001b[34m(path, kwargs)\u001b[39m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bit \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(bits):\n\u001b[32m    357\u001b[39m     protocol = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mprotocol\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m split_protocol(bit)[\u001b[32m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mfile\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m358\u001b[39m     \u001b[38;5;28mcls\u001b[39m = \u001b[43mget_filesystem_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    359\u001b[39m     extra_kwargs = \u001b[38;5;28mcls\u001b[39m._get_kwargs_from_urls(bit)\n\u001b[32m    360\u001b[39m     kws = kwargs.pop(protocol, {})\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\fsspec\\registry.py:266\u001b[39m, in \u001b[36mget_filesystem_class\u001b[39m\u001b[34m(protocol)\u001b[39m\n\u001b[32m    264\u001b[39m         register_implementation(protocol, _import_class(bit[\u001b[33m\"\u001b[39m\u001b[33mclass\u001b[39m\u001b[33m\"\u001b[39m]))\n\u001b[32m    265\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(bit.get(\u001b[33m\"\u001b[39m\u001b[33merr\u001b[39m\u001b[33m\"\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    267\u001b[39m \u001b[38;5;28mcls\u001b[39m = registry[protocol]\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mprotocol\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mabstract\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[31mImportError\u001b[39m: Unable to load filesystem from EntryPoint(name='hf', value='huggingface_hub.HfFileSystem', group='fsspec.specs')"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "\n",
    "raw_df = pd.read_csv(\"raw_data\\DataCoSupplyChainDataset1.csv\")\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "684e7175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Type', 'Days_for_shipping_(real)', 'Days_for_shipment_(scheduled)',\n",
       "       'Benefit_per_order', 'Sales_per_customer', 'Delivery_Status',\n",
       "       'Late_delivery_risk', 'Category_Id', 'Category_Name', 'Customer_City',\n",
       "       'Customer_Country', 'Customer_Email', 'Customer_Fname', 'Customer_Id',\n",
       "       'Customer_Lname', 'Customer_Password', 'Customer_Segment',\n",
       "       'Customer_State', 'Customer_Street', 'Customer_Zipcode',\n",
       "       'Department_Id', 'Department_Name', 'Latitude', 'Longitude', 'Market',\n",
       "       'Order_City', 'Order_Country', 'Order_Customer_Id',\n",
       "       'order_date_(DateOrders)', 'Order_Id', 'Order_Item_Cardprod_Id',\n",
       "       'Order_Item_Discount', 'Order_Item_Discount_Rate', 'Order_Item_Id',\n",
       "       'Order_Item_Product_Price', 'Order_Item_Profit_Ratio',\n",
       "       'Order_Item_Quantity', 'Sales', 'Order_Item_Total',\n",
       "       'Order_Profit_Per_Order', 'Order_Region', 'Order_State', 'Order_Status',\n",
       "       'Order_Zipcode', 'Product_Card_Id', 'Product_Category_Id',\n",
       "       'Product_Description', 'Product_Image', 'Product_Name', 'Product_Price',\n",
       "       'Product_Status', 'shipping_date_(DateOrders)', 'Shipping_Mode'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ceb642a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete usless columns\n",
    "raw_df.drop(columns=['Benefit_per_order', 'Sales_per_customer', 'Late_delivery_risk', 'Category_Id', 'Customer_City',\n",
    "                     'Customer_Email', 'Customer_Id', 'Customer_Password', \n",
    "                     'Customer_Country', 'Department_Name', 'Customer_Fname', 'Customer_Lname',\n",
    "                     'Customer_State', 'Customer_Street', 'Customer_Zipcode', 'Department_Id', 'Latitude', 'Longitude',\n",
    "                     'Order_City', 'Order_Customer_Id', 'Order_Item_Cardprod_Id', 'Order_Item_Discount', 'Order_Item_Discount_Rate',\n",
    "                     'Order_Item_Id', 'Order_Item_Profit_Ratio', 'Order_Item_Total', 'Order_State', 'Order_Zipcode',\n",
    "                     'Product_Category_Id', 'Product_Description', 'Product_Image', 'Product_Status'], inplace = True)\n",
    "\n",
    "#Rename remaining columns\n",
    "raw_df.rename(columns={'shipping_date_(DateOrders)': 'Shipping_Date', 'order_date_(DateOrders)': 'Order_Date', \n",
    "                       'Type': 'Payment_Type', 'Days_for_shipping_(real)': 'Shipment(real)', 'Days_for_shipment_(scheduled)': 'Shipment(scheduled)',\n",
    "                       'Order_Item_Product_Price': 'Item_Price', 'Order_Item_Quantity': 'Item_Quantity', \n",
    "                       'Order_Profit_Per_Order': 'Order_Profit', 'Product_Card_Id': 'Product_Id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b45af47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate delays\n",
    "raw_df['Delay_Days'] = raw_df['Shipment(real)'] - raw_df['Shipment(scheduled)']\n",
    "\n",
    "Q1 = raw_df['Delay_Days'].quantile(0.25)\n",
    "Q3 = raw_df['Delay_Days'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR  \n",
    "upper_bound = Q3 + 1.5 * IQR \n",
    "\n",
    "raw_df['Delay_Type'] = 'Normal'\n",
    "raw_df.loc[raw_df['Delay_Days'] > upper_bound, 'Delay_Type'] = 'Late'\n",
    "raw_df.loc[raw_df['Delay_Days'] < lower_bound, 'Delay_Type'] = 'Early'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4eaaf1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values:\n",
      "Payment_Type           0\n",
      "Shipment(real)         0\n",
      "Shipment(scheduled)    0\n",
      "Delivery_Status        0\n",
      "Category_Name          0\n",
      "Customer_Segment       0\n",
      "Market                 0\n",
      "Order_Country          0\n",
      "Order_Date             0\n",
      "Order_Id               0\n",
      "Item_Price             0\n",
      "Item_Quantity          0\n",
      "Sales                  0\n",
      "Order_Profit           0\n",
      "Order_Region           0\n",
      "Order_Status           0\n",
      "Product_Id             0\n",
      "Product_Name           0\n",
      "Product_Price          0\n",
      "Shipping_Date          0\n",
      "Shipping_Mode          0\n",
      "dtype: int64\n",
      "Duplicate rows: 8\n"
     ]
    }
   ],
   "source": [
    "#There are 0 null values; 0 duplicate rows\n",
    "\n",
    "nulls = raw_df.isna().sum()\n",
    "duplicates = raw_df.duplicated().sum()\n",
    "\n",
    "if duplicates != 0:\n",
    "    raw_df.drop_duplicates(inplace=True)\n",
    "    \n",
    "print(f'Null values:\\n{nulls}\\nDuplicate rows: {duplicates}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ca1173e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Payment_Type                   object\n",
       "Shipment(real)                  int64\n",
       "Shipment(scheduled)             int64\n",
       "Delivery_Status                object\n",
       "Category_Name                  object\n",
       "Customer_Segment               object\n",
       "Market                         object\n",
       "Order_Country                  object\n",
       "Order_Date             datetime64[ns]\n",
       "Order_Id                        int64\n",
       "Item_Price                      int64\n",
       "Item_Quantity                   int64\n",
       "Sales                         float64\n",
       "Order_Profit                  float64\n",
       "Order_Region                   object\n",
       "Order_Status                   object\n",
       "Product_Id                      int64\n",
       "Product_Name                   object\n",
       "Product_Price                 float64\n",
       "Shipping_Date          datetime64[ns]\n",
       "Shipping_Mode                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert date columns into datetime datatype\n",
    "raw_df['Shipping_Date'] = pd.to_datetime(raw_df['Shipping_Date'], errors='coerce')\n",
    "raw_df['Order_Date'] = pd.to_datetime(raw_df['Order_Date'], errors='coerce')\n",
    "\n",
    "raw_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19afecc9",
   "metadata": {},
   "source": [
    "### Profit outlier detection and handling\n",
    "The Order Profit column is filtered for outliers to prevent extreme values from distorting subsequent profit analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02718a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of outliers: 18942 (10.49%)\n"
     ]
    }
   ],
   "source": [
    "#Detecting outliers\n",
    "Q1 = raw_df['Order_Profit'].quantile(0.25)\n",
    "Q3 = raw_df['Order_Profit'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers = raw_df[(raw_df['Order_Profit'] < Q1 - 1.5*IQR) | (raw_df['Order_Profit'] > Q3 + 1.5*IQR)]\n",
    "percentage = len(outliers)/len(raw_df['Order_Profit'])*100\n",
    "\n",
    "print(f'The number of outliers: {len(outliers)} ({round(percentage,2)}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95145822",
   "metadata": {},
   "source": [
    "After identifying outliers in the dataset, approximately **10%** of the observations were classified as extreme values. These observations are likely to represent valid but extreme cases rather than data errors. \n",
    "To reduce their influence on further analyses, outliers will be capped using the ***1stâ€“99th percentile boundary (winsorization)***. This approach limits the impact of extreme values without distorting the overall data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa0b02b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Winsorization\n",
    "lower = raw_df['Order_Profit'].quantile(0.01) \n",
    "upper = raw_df['Order_Profit'].quantile(0.99)\n",
    "\n",
    "raw_df['Profit_Capped'] = raw_df['Order_Profit'].clip(lower, upper)\n",
    "raw_df.drop(columns='Order_Profit', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cbae7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Order_Id', 'Order_Date', 'Order_Status', 'Order_Region', 'Market',\n",
       "       'Order_Country', 'Customer_Segment', 'Product_Id', 'Product_Name',\n",
       "       'Product_Price', 'Category_Name', 'Shipping_Date', 'Shipping_Mode',\n",
       "       'Shipment(real)', 'Shipment(scheduled)', 'Delivery_Status',\n",
       "       'Payment_Type', 'Item_Price', 'Item_Quantity', 'Sales',\n",
       "       'Profit_Capped'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reorder columns for further analysis\n",
    "new_order = [#Order\n",
    "    'Order_Id', 'Order_Date', 'Order_Status', 'Order_Region', 'Market', 'Order_Country',\n",
    "    #Customer\n",
    "    'Customer_Segment',\n",
    "    #Product \n",
    "    'Product_Id', 'Product_Name', 'Product_Price', 'Category_Name',\n",
    "    #Shipping\n",
    "    'Shipping_Date', 'Shipping_Mode', 'Shipment(real)', 'Shipment(scheduled)', 'Delivery_Status', \n",
    "    'Payment_Type', 'Delay_Days',\n",
    "    #Finances\n",
    "    'Item_Price', 'Item_Quantity', 'Sales', 'Profit_Capped']\n",
    "ordered_df = raw_df[[c for c in new_order if c in raw_df.columns]]\n",
    "ordered_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6c1a01",
   "metadata": {},
   "source": [
    "### Country names normalization\n",
    "To enable merging the orders dataset with GDP and population data, country names must first be normalized. Since some country names are not in English, they are translated where necessary and then converted to **ISO3** country codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577a9e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1532\\3337880426.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ordered_df['Order_Country_Normalized'] = ordered_df['Order_Country'].str.lower().str.strip()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1532\\3337880426.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ordered_df['Order_Country_Normalized'] = ordered_df['Order_Country_Normalized'].replace(manual_fixes)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1532\\3337880426.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ordered_df['ISO3'] = ordered_df['Order_Country_Normalized'].apply(get_iso3)\n"
     ]
    }
   ],
   "source": [
    "#Normalize country names\n",
    "ordered_df['Order_Country_Normalized'] = ordered_df['Order_Country'].str.lower().str.strip()\n",
    "\n",
    "manual_fixes = {\n",
    "    'martinica': 'france',\n",
    "    'guadalupe': 'france',\n",
    "    'french guiana': 'france',\n",
    "    'sahara occidental': None\n",
    "}\n",
    "\n",
    "ordered_df['Order_Country_Normalized'] = ordered_df['Order_Country_Normalized'].replace(manual_fixes)\n",
    "\n",
    "#Assign the ISO code to each country\n",
    "def get_iso3(name):\n",
    "    if pd.isna(name):\n",
    "        return None\n",
    "    try:\n",
    "        return pycountry.countries.lookup(name).alpha_3\n",
    "    except LookupError:\n",
    "        return None\n",
    "\n",
    "ordered_df['ISO3'] = ordered_df['Order_Country_Normalized'].apply(get_iso3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dce5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mismatched countries count\n",
    "mis_len = len(ordered_df[ordered_df['ISO3'].isna()]['Order_Country_Normalized'].unique())\n",
    "print(f'The number of mismatched country names is {mis_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d15beb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1532\\3070785409.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ordered_df['Order_Country_Normalized'] = ordered_df['Order_Country'].str.strip().str.title()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1532\\3070785409.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ordered_df['Order_Country_Translated'] = ordered_df['Order_Country_Normalized'].map(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries still needing manual handling:\n",
      "['Democratic Republic of Congo' 'Ivory Coast' 'Italia' 'Espana' 'Irak'\n",
      " 'Arabia Saudi' 'Filipinas' 'Myanmar (Burmania)' 'Rumania'\n",
      " 'Trinity of Y Tobago' 'Russia' 'Belgica' 'Kirguistan' 'Camboya' 'Lesoto'\n",
      " 'Swiss' 'Barein' 'Macedonia' 'Azerbaiyan' 'Moldavia' 'Tune' 'Yibuti'\n",
      " 'Swaziland' 'Surinam' 'Belice' 'Republic Of Gambia' None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1532\\3070785409.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ordered_df['ISO3_Final'] = ordered_df['Order_Country_Translated'].apply(country_to_iso)\n"
     ]
    }
   ],
   "source": [
    "ordered_df['Order_Country_Normalized'] = ordered_df['Order_Country'].str.strip().str.title()\n",
    "\n",
    "mismatched = ordered_df[ordered_df['ISO3'].isna()]['Order_Country_Normalized'].unique()\n",
    "\n",
    "#Fixes for territories\n",
    "manual_translations = {\n",
    "    'Martinica': 'France',\n",
    "    'Guadalupe': 'France',\n",
    "    'French Guiana': 'France',\n",
    "    'Sahara Occidental': None,\n",
    "    'Hong Kong': 'China',\n",
    "    'Taiwan': 'Taiwan',\n",
    "}\n",
    "\n",
    "#Auto-translate\n",
    "to_translate = [c for c in mismatched if c not in manual_translations and pd.notna(c)]\n",
    "translated_list = GoogleTranslator(source='auto', target='en').translate_batch(to_translate)\n",
    "translated_mapping = dict(zip(to_translate, translated_list))\n",
    "translated_mapping.update(manual_translations)  # combine\n",
    "\n",
    "#Map normalized and translated names\n",
    "ordered_df['Order_Country_Translated'] = ordered_df['Order_Country_Normalized'].map(\n",
    "    lambda x: translated_mapping.get(x, x))\n",
    "\n",
    "#Map them to ISO3\n",
    "def country_to_iso(name):\n",
    "    if name is None:\n",
    "        return None\n",
    "    try:\n",
    "        return pycountry.countries.lookup(name).alpha_3\n",
    "    except LookupError:\n",
    "        return None\n",
    "\n",
    "ordered_df['ISO3_Final'] = ordered_df['Order_Country_Translated'].apply(country_to_iso)\n",
    "\n",
    "#Check for remaining unmatched\n",
    "remaining_unmatched = ordered_df[ordered_df['ISO3_Final'].isna()]['Order_Country_Translated'].unique()\n",
    "print(\"Countries still needing manual handling:\")\n",
    "print(remaining_unmatched)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6966692e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1532\\1106431376.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ordered_df['Order_Country_Translated_Final'] = ordered_df['Order_Country_Translated'].map(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries still needing manual handling:\n",
      "['Myanmar (Burmania)']\n"
     ]
    }
   ],
   "source": [
    "#Manual translation\n",
    "manual_translations_final = {\n",
    "    'Democratic Republic of Congo': 'Congo',\n",
    "    'Ivory Coast': 'CÃ´te d\\'Ivoire',\n",
    "    'Italia': 'Italy',\n",
    "    'Espana': 'Spain',\n",
    "    'Irak': 'Iraq',\n",
    "    'Arabia Saudi': 'Saudi Arabia',\n",
    "    'Filipinas': 'Philippines',\n",
    "    'Myanmar (Birmania)': 'Myanmar',\n",
    "    'Rumania': 'Romania',\n",
    "    'Trinity of Y Tobago': 'Trinidad and Tobago',\n",
    "    'Russia': 'Russian Federation',\n",
    "    'Belgica': 'Belgium',\n",
    "    'Kirguistan': 'Kyrgyzstan',\n",
    "    'Camboya': 'Cambodia',\n",
    "    'Lesoto': 'Lesotho',\n",
    "    'Swiss': 'Switzerland',\n",
    "    'Barein': 'Bahrain',\n",
    "    'Macedonia': 'North Macedonia',\n",
    "    'Azerbaiyan': 'Azerbaijan',\n",
    "    'Moldavia': 'Moldova',\n",
    "    'Tune': 'Tunisia',\n",
    "    'Yibuti': 'Djibouti',\n",
    "    'Swaziland': 'Eswatini',\n",
    "    'Surinam': 'Suriname',\n",
    "    'Belice': 'Belize',\n",
    "    'Republic Of Gambia': 'Gambia',\n",
    "    None: None\n",
    "}\n",
    "\n",
    "#Final translation\n",
    "ordered_df['Order_Country_Translated_Final'] = ordered_df['Order_Country_Translated'].map(\n",
    "    lambda x: manual_translations_final.get(x, x)\n",
    ")\n",
    "ordered_df = ordered_df.dropna(subset=['Order_Country_Translated_Final'])\n",
    "\n",
    "#Map to ISO3\n",
    "ordered_df['ISO3_Final'] = ordered_df['Order_Country_Translated_Final'].apply(country_to_iso)\n",
    "\n",
    "#Check for remaining unmatched\n",
    "remaining_unmatched = ordered_df[ordered_df['ISO3_Final'].isna()]['Order_Country_Translated_Final'].unique()\n",
    "print(\"Countries still needing manual handling:\")\n",
    "print(remaining_unmatched)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1951bf",
   "metadata": {},
   "source": [
    "### Final corrections\n",
    "The final step is to reorder columns and save the datframe to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f25cbed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Order_Id', 'Order_Date', 'Order_Status', 'Order_Region', 'Market',\n",
       "       'ISO3', 'Customer_Segment', 'Product_Id', 'Product_Name',\n",
       "       'Category_Name', 'Product_Price', 'Shipping_Date', 'Shipping_Mode',\n",
       "       'Shipment(real)', 'Shipment(scheduled)', 'Delivery_Status',\n",
       "       'Payment_Type', 'Item_Price', 'Item_Quantity', 'Sales',\n",
       "       'Profit_Capped'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop and rename columns\n",
    "\n",
    "ordered_df.drop(columns=['Order_Country', 'Order_Country_Normalized', 'ISO3', 'Order_Country_Translated', 'Order_Country_Translated_Final'], inplace=True)\n",
    "ordered_df.rename(columns={'ISO3_Final': 'ISO3'}, inplace=True)\n",
    "\n",
    "#Reorder columns for further analysis\n",
    "\n",
    "new_order = [#Order\n",
    "    'Order_Id', 'Order_Date', 'Order_Status', 'Order_Region', 'Market', 'ISO3',\n",
    "    #Customer\n",
    "    'Customer_Segment',\n",
    "    #Product \n",
    "    'Product_Id', 'Product_Name', 'Category_Name', 'Product_Price',\n",
    "    #Shipping\n",
    "    'Shipping_Date', 'Shipping_Mode', 'Shipment(real)', 'Shipment(scheduled)', 'Delivery_Status', 'Payment_Type',\n",
    "    #Finances\n",
    "    'Item_Price', 'Item_Quantity', 'Sales', 'Profit_Capped']\n",
    "ordered_df = ordered_df[[c for c in new_order if c in ordered_df.columns]]\n",
    "\n",
    "ordered_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69ff2287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to transformed\\orders_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "#Save to csv\n",
    "csv_file = os.path.join('transformed', 'orders_cleaned.csv')\n",
    "os.makedirs(os.path.dirname(csv_file), exist_ok=True)\n",
    "\n",
    "ordered_df.to_csv(csv_file, index=False)\n",
    "\n",
    "print(f'Data saved to {csv_file}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
